{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302a0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, TimeDistributed, Input, RepeatVector, Embedding\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb81eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "en=pd.read_csv('small_vocab_en.csv', header=None, sep='\\t')\n",
    "fr=pd.read_csv('small_vocab_fr.csv', header=None, sep='\\t')\n",
    "\n",
    "en=en.rename(columns={0:\"English\"})\n",
    "fr=fr.rename(columns={0:\"French\"})\n",
    "\n",
    "df = en.join(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['French'] = df['French'].apply(lambda x: ' '.join(['sos', x, 'eos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b43efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, test_en, train_fr, test_fr = train_test_split(df['English'], df['French'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437b5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_token = text.Tokenizer()\n",
    "fr_token = text.Tokenizer()\n",
    "en_token.fit_on_texts(list(train_en))\n",
    "fr_token.fit_on_texts(list(train_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(series,tokenizer, vocab, maxlen, reverse=False, train=False):\n",
    "    seq = tokenizer.texts_to_sequences(series)\n",
    "    \n",
    "    if train:\n",
    "        vocab = len(tokenizer.word_index) + 1\n",
    "        maxlen = max([len(sen) for sen in seq])\n",
    "    \n",
    "    seq = sequence.pad_sequences(seq, maxlen=maxlen, padding='post')\n",
    "    if reverse:\n",
    "        seq = seq[:, ::-1]\n",
    "    return (seq, vocab, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cb87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_seq, en_vocab, en_len = preprocess(train_en, en_token, reverse=True)\n",
    "fr_seq, fr_vocab, fr_len = preprocess(train_fr, fr_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7669b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_x = fr_seq[:,:-1]\n",
    "fr_cat = to_categorical(fr_seq, num_classes=fr_vocab)\n",
    "fr_y = fr_cat[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f0a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TeacherForcing\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 96)       19200       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 22, 96)       33216       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru (GRU)                      [(None, 48),         21024       ['embedding[0][0]']              \n",
      "                                 (None, 48)]                                                      \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 22, 48)       21024       ['embedding_1[0][0]',            \n",
      "                                                                  'gru[0][1]']                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 22, 346)     16954       ['gru_1[0][0]']                  \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111,418\n",
      "Trainable params: 111,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#encoder\n",
    "en_inp = Input(shape=(en_len,))\n",
    "tr_en_emb = Embedding(en_vocab, 96, input_length=en_len)\n",
    "tr_emb = tr_en_emb(en_inp)\n",
    "tr_en_gru = GRU(48, return_state=True)\n",
    "_, en_state = tr_en_gru(tr_emb)\n",
    "\n",
    "#decoder\n",
    "de_inp = Input(shape=(fr_len-1,))\n",
    "tr_de_emb = Embedding(fr_vocab, 96, input_length=fr_len-1)\n",
    "tr_de_emb_ = tr_de_emb(de_inp)\n",
    "tr_de_gru = GRU(48, return_sequences=True)\n",
    "de_out = tr_de_gru(tr_de_emb_, initial_state=en_state)\n",
    "\n",
    "#prediction\n",
    "tr_dense = Dense(fr_vocab, activation='softmax')\n",
    "de_pred = TimeDistributed(tr_dense)(de_out)\n",
    "\n",
    "model = Model(inputs=[en_inp, de_inp], outputs=de_pred, name=\"TeacherForcing\")\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c21bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1379/1379 [==============================] - 643s 287ms/step - loss: 1.2377 - acc: 0.7022 - val_loss: 0.5862 - val_acc: 0.8150\n",
      "Epoch 2/30\n",
      "1379/1379 [==============================] - 173s 123ms/step - loss: 0.4796 - acc: 0.8435 - val_loss: 0.4039 - val_acc: 0.8660\n",
      "Epoch 3/30\n",
      "1379/1379 [==============================] - 89s 64ms/step - loss: 0.3522 - acc: 0.8824 - val_loss: 0.3143 - val_acc: 0.8937\n",
      "Epoch 4/30\n",
      "1379/1379 [==============================] - 89s 65ms/step - loss: 0.2784 - acc: 0.9073 - val_loss: 0.2523 - val_acc: 0.9166\n",
      "Epoch 5/30\n",
      "1379/1379 [==============================] - 89s 65ms/step - loss: 0.2284 - acc: 0.9254 - val_loss: 0.2130 - val_acc: 0.9313\n",
      "Epoch 6/30\n",
      "1379/1379 [==============================] - 90s 65ms/step - loss: 0.1933 - acc: 0.9382 - val_loss: 0.1849 - val_acc: 0.9411\n",
      "Epoch 7/30\n",
      "1379/1379 [==============================] - 91s 66ms/step - loss: 0.1677 - acc: 0.9470 - val_loss: 0.1603 - val_acc: 0.9499\n",
      "Epoch 8/30\n",
      "1379/1379 [==============================] - 91s 66ms/step - loss: 0.1490 - acc: 0.9528 - val_loss: 0.1496 - val_acc: 0.9515\n",
      "Epoch 9/30\n",
      "1379/1379 [==============================] - 189s 137ms/step - loss: 0.1342 - acc: 0.9570 - val_loss: 0.1380 - val_acc: 0.9551\n",
      "Epoch 10/30\n",
      "1379/1379 [==============================] - 96s 69ms/step - loss: 0.1234 - acc: 0.9597 - val_loss: 0.1221 - val_acc: 0.9596\n",
      "Epoch 11/30\n",
      "1379/1379 [==============================] - 212s 154ms/step - loss: 0.1137 - acc: 0.9623 - val_loss: 0.1171 - val_acc: 0.9602\n",
      "Epoch 12/30\n",
      "1379/1379 [==============================] - 97s 70ms/step - loss: 0.1071 - acc: 0.9640 - val_loss: 0.1029 - val_acc: 0.9665\n",
      "Epoch 13/30\n",
      "1379/1379 [==============================] - 95s 69ms/step - loss: 0.0990 - acc: 0.9667 - val_loss: 0.1058 - val_acc: 0.9639\n",
      "Epoch 14/30\n",
      "1379/1379 [==============================] - 97s 71ms/step - loss: 0.0940 - acc: 0.9684 - val_loss: 0.0968 - val_acc: 0.9674\n",
      "Epoch 15/30\n",
      "1379/1379 [==============================] - 98s 71ms/step - loss: 0.0892 - acc: 0.9698 - val_loss: 0.0920 - val_acc: 0.9689\n",
      "Epoch 16/30\n",
      "1379/1379 [==============================] - 101s 73ms/step - loss: 0.0844 - acc: 0.9716 - val_loss: 0.0813 - val_acc: 0.9737\n",
      "Epoch 17/30\n",
      "1379/1379 [==============================] - 97s 70ms/step - loss: 0.0794 - acc: 0.9734 - val_loss: 0.0787 - val_acc: 0.9743\n",
      "Epoch 18/30\n",
      "1379/1379 [==============================] - 99s 72ms/step - loss: 0.0765 - acc: 0.9742 - val_loss: 0.0822 - val_acc: 0.9715\n",
      "Epoch 19/30\n",
      "1379/1379 [==============================] - 98s 71ms/step - loss: 0.0735 - acc: 0.9752 - val_loss: 0.0706 - val_acc: 0.9780\n",
      "Epoch 20/30\n",
      "1379/1379 [==============================] - 97s 70ms/step - loss: 0.0710 - acc: 0.9763 - val_loss: 0.0719 - val_acc: 0.9763\n",
      "Epoch 21/30\n",
      "1379/1379 [==============================] - 98s 71ms/step - loss: 0.0679 - acc: 0.9772 - val_loss: 0.0694 - val_acc: 0.9778\n",
      "Epoch 22/30\n",
      "1379/1379 [==============================] - 97s 70ms/step - loss: 0.0660 - acc: 0.9780 - val_loss: 0.0691 - val_acc: 0.9774\n",
      "Epoch 23/30\n",
      "1379/1379 [==============================] - 97s 71ms/step - loss: 0.0637 - acc: 0.9787 - val_loss: 0.0628 - val_acc: 0.9805\n",
      "Epoch 24/30\n",
      "1379/1379 [==============================] - 98s 71ms/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.0623 - val_acc: 0.9806\n",
      "Epoch 25/30\n",
      "1379/1379 [==============================] - 98s 71ms/step - loss: 0.0599 - acc: 0.9801 - val_loss: 0.0627 - val_acc: 0.9799\n",
      "Epoch 26/30\n",
      "1379/1379 [==============================] - 400s 290ms/step - loss: 0.0569 - acc: 0.9816 - val_loss: 0.0612 - val_acc: 0.9801\n",
      "Epoch 27/30\n",
      "1379/1379 [==============================] - 102s 74ms/step - loss: 0.0558 - acc: 0.9817 - val_loss: 0.0574 - val_acc: 0.9821\n",
      "Epoch 28/30\n",
      "1379/1379 [==============================] - 96s 70ms/step - loss: 0.0538 - acc: 0.9826 - val_loss: 0.0637 - val_acc: 0.9791\n",
      "Epoch 29/30\n",
      "1379/1379 [==============================] - 100s 73ms/step - loss: 0.0532 - acc: 0.9827 - val_loss: 0.0627 - val_acc: 0.9787\n",
      "Epoch 30/30\n",
      "1379/1379 [==============================] - 103s 75ms/step - loss: 0.0510 - acc: 0.9835 - val_loss: 0.0704 - val_acc: 0.9756\n"
     ]
    }
   ],
   "source": [
    "# Implement callbacks to handle overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "model_save = ModelCheckpoint('best_model.hdf5', save_best_only=True)\n",
    "\n",
    "history = model.fit([en_seq, fr_x], fr_y, batch_size=64, epochs=30, validation_split=0.2, callbacks=[early_stopping, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08b9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "en_inp = Input(shape=(en_len,))\n",
    "en_emb = Embedding(en_vocab, 96, input_length=en_len)\n",
    "emb = en_emb(en_inp)\n",
    "en_gru = GRU(48, return_state=True)\n",
    "_, en_state = en_gru(emb)\n",
    "encoder = Model(inputs=en_inp, outputs=en_state)\n",
    "\n",
    "en_emb.set_weights(tr_en_emb.get_weights())\n",
    "en_gru.set_weights(tr_en_gru.get_weights())\n",
    "\n",
    "#decoder\n",
    "de_inp = Input(shape=(1,))\n",
    "de_emb = Embedding(fr_vocab, 96, input_length=fr_len-1)\n",
    "de_emb_ = de_emb(de_inp)\n",
    "de_inp_state = Input(shape=(48,))\n",
    "de_gru = GRU(48, return_state=True)\n",
    "de_out, de_out_state = de_gru(de_emb_, initial_state=de_inp_state)\n",
    "\n",
    "#prediction\n",
    "dense = Dense(fr_vocab, activation='softmax')\n",
    "de_pred = dense(de_out)\n",
    "\n",
    "de_emb.set_weights(tr_de_emb.get_weights())\n",
    "de_gru.set_weights(tr_de_gru.get_weights())\n",
    "dense.set_weights(tr_dense.get_weights())\n",
    "\n",
    "decoder = Model(inputs=[de_inp, de_inp_state], outputs=[de_pred, de_out_state], name=\"Translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d62f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.04314193e-01, 7.97056110e-09, 5.12304045e-12, 4.53365535e-13,\n",
      "        1.17453780e-08, 7.49214094e-11, 1.21905641e-05, 1.04647205e-12,\n",
      "        7.61238515e-01, 3.31550954e-12, 9.14068642e-06, 3.94917129e-12,\n",
      "        2.07047854e-02, 3.50291209e-08, 4.79963717e-07, 3.85369722e-11,\n",
      "        3.26137693e-11, 2.37944904e-14, 5.99843580e-13, 3.68029522e-12,\n",
      "        6.61693322e-09, 6.69743260e-17, 1.83020294e-15, 3.95958627e-16,\n",
      "        2.42556825e-06, 9.09641150e-14, 8.69623040e-10, 7.61472760e-11,\n",
      "        3.07925343e-14, 7.33144218e-14, 4.37942159e-04, 8.67038565e-08,\n",
      "        2.64472146e-12, 7.72085566e-16, 3.40975945e-12, 2.69009363e-11,\n",
      "        5.06725868e-12, 1.08122543e-13, 1.74982607e-15, 9.17021171e-05,\n",
      "        5.94996987e-03, 3.77015422e-05, 4.09189990e-19, 2.29495937e-14,\n",
      "        1.87519089e-09, 5.73398135e-11, 4.29622152e-16, 4.15466446e-12,\n",
      "        3.49698162e-13, 5.91300175e-13, 6.94742267e-12, 1.68264870e-13,\n",
      "        1.90349714e-09, 6.32683328e-09, 3.86832996e-11, 3.71211444e-14,\n",
      "        8.09739845e-11, 4.13686330e-09, 4.75732125e-14, 2.02009396e-14,\n",
      "        4.60982842e-14, 1.39918544e-17, 8.87102475e-11, 1.69518516e-14,\n",
      "        6.15405689e-15, 3.27794339e-17, 8.88374780e-06, 2.34742767e-16,\n",
      "        2.27625936e-20, 4.55246243e-19, 2.86753455e-12, 4.19177959e-05,\n",
      "        1.73258150e-13, 1.62137681e-08, 2.28024658e-14, 1.61034333e-08,\n",
      "        2.09478719e-11, 1.02586625e-03, 9.62078047e-07, 5.56047410e-02,\n",
      "        1.50658025e-05, 1.29605189e-15, 5.07601690e-05, 2.47943532e-08,\n",
      "        1.82769577e-10, 1.38272301e-14, 1.45057690e-11, 4.57169940e-16,\n",
      "        1.21401698e-08, 1.21965044e-07, 1.15938942e-11, 4.81815210e-16,\n",
      "        7.67976133e-16, 9.28096489e-12, 2.23120536e-10, 1.07507051e-17,\n",
      "        1.35641012e-11, 1.69431732e-12, 2.80266162e-17, 3.51198281e-12,\n",
      "        7.33884820e-09, 2.07672213e-11, 4.81393883e-11, 8.69634497e-14,\n",
      "        2.31334492e-16, 6.82458918e-14, 3.47002592e-13, 9.71002834e-10,\n",
      "        4.46995578e-08, 3.87220291e-16, 1.57858426e-09, 3.04481445e-17,\n",
      "        5.45831380e-10, 4.23179075e-10, 1.51724203e-06, 4.32747777e-14,\n",
      "        1.35188182e-12, 6.79119421e-06, 1.36504386e-09, 3.55558044e-18,\n",
      "        8.98756379e-16, 7.46805195e-09, 3.22063817e-12, 9.36782780e-15,\n",
      "        1.41519840e-09, 4.58607327e-13, 6.20400388e-15, 4.84610182e-14,\n",
      "        6.09391222e-08, 5.55409802e-19, 5.07123787e-10, 3.89697476e-11,\n",
      "        2.67497989e-18, 3.01136172e-10, 2.43864000e-12, 3.55863586e-13,\n",
      "        3.36676081e-14, 1.93420258e-13, 2.55455413e-14, 6.02290612e-15,\n",
      "        2.82141796e-13, 2.56110136e-14, 1.42379435e-13, 3.51955583e-11,\n",
      "        1.38986991e-18, 7.61244453e-12, 1.62925040e-16, 8.75659933e-10,\n",
      "        8.01023484e-12, 3.10273833e-16, 5.23629495e-08, 1.04830975e-16,\n",
      "        4.07039062e-16, 8.21734770e-13, 1.03804378e-11, 8.33526160e-14,\n",
      "        3.69712420e-12, 3.88118162e-15, 8.13350153e-17, 1.06805988e-10,\n",
      "        6.68587141e-09, 3.65861097e-09, 1.85804795e-13, 4.22445312e-02,\n",
      "        1.68905450e-16, 1.23455524e-10, 1.07702652e-13, 8.52639973e-11,\n",
      "        4.38853657e-15, 2.83669165e-11, 8.20064477e-16, 1.26771437e-13,\n",
      "        7.82212904e-15, 3.71275717e-15, 1.34430024e-14, 6.38391876e-15,\n",
      "        1.46029615e-14, 1.37624971e-15, 5.08204318e-14, 4.83657439e-13,\n",
      "        6.37967394e-14, 1.64537076e-16, 9.30600649e-13, 1.39140410e-09,\n",
      "        1.40421313e-15, 4.90011683e-16, 3.50012410e-17, 2.58679168e-18,\n",
      "        1.64034476e-12, 2.31945970e-16, 9.85743592e-16, 2.16700586e-13,\n",
      "        1.99622083e-10, 1.82159484e-14, 4.03555553e-13, 3.26762956e-18,\n",
      "        1.54790060e-17, 7.85525650e-16, 4.91916396e-16, 2.05280168e-11,\n",
      "        5.02435170e-13, 3.70013087e-15, 4.52159199e-09, 4.42158898e-06,\n",
      "        3.71843424e-11, 3.10188564e-09, 1.05026238e-10, 1.03607791e-14,\n",
      "        1.54848721e-11, 1.73690076e-08, 2.91533968e-14, 6.75597707e-13,\n",
      "        1.81207497e-11, 4.31037281e-12, 2.39738170e-16, 5.81300830e-09,\n",
      "        7.24292960e-15, 2.59683247e-10, 3.74601272e-18, 4.79616525e-16,\n",
      "        2.73215426e-11, 4.61425134e-11, 3.17001633e-13, 6.90820122e-13,\n",
      "        6.64871693e-15, 1.37802342e-14, 8.68935966e-19, 1.36805276e-15,\n",
      "        1.11083721e-14, 2.50540853e-13, 3.28064031e-20, 1.38648075e-18,\n",
      "        2.91054642e-13, 1.77046352e-14, 5.88877769e-14, 2.18367643e-10,\n",
      "        7.57709867e-12, 2.28292537e-12, 8.19483493e-03, 5.76425713e-11,\n",
      "        1.43772508e-10, 1.27298705e-09, 1.70930537e-14, 1.73806607e-13,\n",
      "        1.57178274e-12, 5.58983719e-12, 2.47288886e-12, 3.72852221e-13,\n",
      "        3.77148091e-09, 7.99900792e-17, 5.53269670e-12, 3.13536598e-14,\n",
      "        1.25560728e-10, 3.68397837e-14, 2.40566473e-11, 4.94299735e-16,\n",
      "        1.49888556e-11, 3.06727255e-10, 2.53373537e-15, 7.22016102e-14,\n",
      "        1.38740291e-16, 2.35672306e-16, 7.35263615e-16, 1.82911496e-14,\n",
      "        3.65830853e-14, 3.29455463e-09, 2.96498377e-15, 7.02996914e-17,\n",
      "        4.60017982e-16, 6.52113620e-16, 1.84052996e-15, 8.17356288e-17,\n",
      "        2.48401045e-13, 1.34099863e-15, 1.17321754e-14, 5.89147075e-15,\n",
      "        1.31886439e-15, 3.01785155e-15, 5.36195361e-15, 4.55136935e-11,\n",
      "        1.00152566e-13, 1.11532872e-08, 3.33175036e-16, 6.51144508e-15,\n",
      "        1.24975876e-13, 6.03926402e-15, 9.76522752e-10, 5.74342726e-11,\n",
      "        2.95005529e-13, 1.43003692e-14, 8.62541646e-13, 6.08024655e-12,\n",
      "        1.33489947e-15, 4.75480932e-10, 2.69287110e-11, 7.41442741e-10,\n",
      "        2.52858037e-14, 1.00797239e-13, 1.56657338e-14, 1.14516086e-08,\n",
      "        2.50658088e-12, 3.21154588e-13, 4.29974321e-14, 3.03825498e-12,\n",
      "        9.60113766e-09, 3.02331322e-15, 2.90871351e-14, 1.37795848e-13,\n",
      "        2.21101137e-09, 2.11598902e-12, 6.98799937e-15, 8.03710831e-12,\n",
      "        1.30897165e-13, 4.64649846e-10, 3.86449012e-10, 1.19112969e-10,\n",
      "        3.37951607e-12, 1.55646745e-11, 2.06368757e-15, 8.10679857e-10,\n",
      "        8.16961006e-08, 7.05474599e-15, 8.86285229e-12, 1.27423376e-12,\n",
      "        1.92600509e-16, 5.87579430e-11, 1.20576961e-15, 1.67155591e-12,\n",
      "        8.34878109e-15, 1.51506793e-11, 1.24685635e-13, 1.28171204e-12,\n",
      "        1.01141691e-11, 3.40307040e-14, 8.25679469e-10, 6.44343899e-13,\n",
      "        2.61642982e-11, 3.87590323e-13, 5.77899621e-15, 4.20967328e-15,\n",
      "        1.56301567e-14, 7.89988497e-15, 7.44357646e-13, 1.04781960e-13,\n",
      "        1.30069338e-14, 5.47507482e-12]], dtype=float32), array([[-1.        , -0.9999996 , -0.99670357,  0.99997765, -0.9311651 ,\n",
      "        -0.8052434 ,  0.99244726,  1.        , -0.99999857,  0.9989438 ,\n",
      "        -0.9764235 ,  0.9053349 ,  0.9999941 ,  0.9222207 ,  0.9974389 ,\n",
      "         0.9999688 , -0.99956495,  1.        , -0.99999595, -1.        ,\n",
      "        -1.        ,  0.9995884 , -1.        , -0.95871234,  0.97885025,\n",
      "         0.77843976,  0.78823304, -0.97735256, -1.        , -0.26435205,\n",
      "         1.        ,  1.        , -0.99999195, -0.99999964,  0.9998526 ,\n",
      "        -0.9906818 ,  0.3789654 , -0.9998963 ,  0.8787177 , -0.9660517 ,\n",
      "        -0.9999979 , -0.9986521 , -0.9991708 , -0.98848665,  1.        ,\n",
      "         0.98252034,  0.00207423,  0.34335673]], dtype=float32)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\", '(<class \\'tuple\\'> containing values of types {\"<class \\'numpy.ndarray\\'>\", \"<class \\'int\\'>\"})'}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m fr_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fr_len):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mde_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mde_s_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m     pred \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mpredict([de_new, de_s_t])\n\u001b[0;32m     11\u001b[0m     de_prob, de_s_t \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m], pred[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\data_adapter.py:984\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    981\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    983\u001b[0m   \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m--> 984\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    987\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\", '(<class \\'tuple\\'> containing values of types {\"<class \\'numpy.ndarray\\'>\", \"<class \\'int\\'>\"})'}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "lis = [test_en[7170]]\n",
    "en_new, _, _ = preprocess(lis, en_token, en_vocab, en_len, reverse=True)\n",
    "de_s_t = encoder.predict(en_new)\n",
    "de_new, _, _ =preprocess(['sos'], fr_token, fr_vocab, fr_len)\n",
    "\n",
    "fr_sent = ''\n",
    "\n",
    "for i in range(fr_len):\n",
    "    print(decoder.predict([de_new, de_s_t]))\n",
    "    pred = decoder.predict([de_new, de_s_t])\n",
    "    de_prob, de_s_t = pred[0], pred[1]\n",
    "    \n",
    "    try:\n",
    "        de_w = fr_token.index_word[np.argmax(de_prob, axis=-1)[0]]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    de_new = preprocess([de_w], fr_token, fr_vocab, fr_len)\n",
    "    \n",
    "    if de_w == 'eos':break\n",
    "    \n",
    "    fr_sent += de_w + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce3fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
