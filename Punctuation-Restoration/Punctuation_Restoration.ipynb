{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc147130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk import wordpunct_tokenize\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "from transformers import AutoTokenizer, TFAutoModelForTokenClassification, DataCollatorForTokenClassification, create_optimizer\n",
    "from datasets import ClassLabel, Sequence, Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb479bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2id = {',':1,'.':2,'!':3, '?':4, \"'\":5,'NaN':0}\n",
    "id2lab = {v:k for k,v in lab2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a12bbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_polarity (C:/Users/Wonder-David Efe/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/14f90415c754f47cf9087eadac25823a395fef4400c7903c5897f55cfaaa6f61)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.07305145263671875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b27c2051b0a4f389fd9a86dfe570f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('yelp_polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832ff4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1619b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['validation'] = df['test']\n",
    "dataset['train'] = df['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68f62a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 504000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 38000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 56000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad440b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    lab, tokens = [], []\n",
    "    tok = wordpunct_tokenize(text['text'])\n",
    "    if len(tok) != 1:\n",
    "        while tok[0] in lab2id.keys():\n",
    "            del tok[0]\n",
    "        for i in range(len(tok)):\n",
    "            if tok[i] in lab2id.keys():\n",
    "                lab[-1] = lab2id[tok[i]]\n",
    "            else:\n",
    "                lab.append(0)\n",
    "                tokens.append(tok[i])\n",
    "    return {'tokens':tokens, 'tag':lab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102af509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.058249473571777344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 560000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f6600b56d64255a51045bc91a18375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/Wonder-David Efe/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/14f90415c754f47cf9087eadac25823a395fef4400c7903c5897f55cfaaa6f61\\cache-6cf3c50b2b580dd7.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f148ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04353475570678711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 560,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17aa7de6ca2497896309cfea37493a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.043473005294799805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 38,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2000af5e54aa4ecc97d4a28d4e0f0185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda example: len(example['tokens']) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f80eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].features['tag']=Sequence(feature=ClassLabel(num_classes=6, names=['Nan', ',', '.', '!', '?', \"'\"]))\n",
    "dataset['test'].features['tag']=Sequence(feature=ClassLabel(num_classes=6, names=['Nan', ',', '.', '!', '?', \"'\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30d4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=dataset['train'].features['tag'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523106b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=4, id2label=id2lab, label2id=lab2id, from_pt=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d2ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tag\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word:\n",
    "                label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word = word_id\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a1ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0455474853515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 45,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd9d91353f54ca884680e4b3b3925e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04536557197570801,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 12,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3147ea32073044cdae10e1fe6d5d2170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_df = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1f962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b688e323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    }
   ],
   "source": [
    "tf_train_df = model.prepare_tf_dataset(\n",
    "    tok_df['train'],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=16,\n",
    ")\n",
    "tf_test_df = model.prepare_tf_dataset(\n",
    "    tok_df['test'],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffc9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_df) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50e77fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_validation_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metric_callback \u001b[38;5;241m=\u001b[39m KerasMetricCallback(metric_fn\u001b[38;5;241m=\u001b[39mcompute_metrics, eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtf_validation_set\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_validation_set' is not defined"
     ]
    }
   ],
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e54305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   1/5502 [..............................] - ETA: 186:23:12 - loss: 1.3677"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul' defined at (most recent call last):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Wonder-David Efe\\AppData\\Local\\Temp\\ipykernel_21956\\479624844.py\", line 1, in <module>\n      model.fit(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1495, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1892, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 873, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 558, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 564, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 520, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 424, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul'\nOOM when allocating tensor with shape[8,491,3072] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27437]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_train_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;43;03m#     callbacks=[callback],\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul' defined at (most recent call last):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Wonder-David Efe\\AppData\\Local\\Temp\\ipykernel_21956\\479624844.py\", line 1, in <module>\n      model.fit(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1495, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1892, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 873, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 558, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 564, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 520, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 424, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul'\nOOM when allocating tensor with shape[8,491,3072] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27437]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    tf_train_df,\n",
    "    callbacks=[metric_callback],\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18fa99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ac98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
