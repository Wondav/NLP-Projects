{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc147130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk import wordpunct_tokenize\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from transformers import AutoTokenizer, TFAutoModelForTokenClassification, DataCollatorForTokenClassification, create_optimizer\n",
    "from datasets import ClassLabel, Sequence, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0184fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2id = {',':1,'.':2,'!':3,'NaN':0}\n",
    "id2lab = {v:k for k,v in lab2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f0e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('review-Copy1.csv')\n",
    "df = df.dropna(axis=0, subset=['reviewText'])\n",
    "df = df[[\"reviewText\"]]\n",
    "dataset = Dataset.from_pandas(df)\n",
    "# dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10068068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    lab, tokens = [], []\n",
    "    tok = wordpunct_tokenize(text['reviewText'])\n",
    "    while tok[0] in lab2id.keys():\n",
    "        del tok[0]\n",
    "    for i in range(len(tok)):\n",
    "        if tok[i] in lab2id.keys():\n",
    "            lab[-1] = lab2id[tok[i]]\n",
    "        else:\n",
    "            lab.append(0)\n",
    "            tokens.append(tok[i])\n",
    "    return {'tokens':tokens, 'tag':lab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3c7bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.13372182846069336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 55014,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a48b7bc9cc4c0b8f849efff103baf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55014 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111f22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features['tag']=Sequence(feature=ClassLabel(num_classes=4, names=['Nan', ',', '.', '!']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db477ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523106b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint, id2label=id2lab, label2id=lab2id, from_pt=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9d8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d2ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"tag\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a1ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04990124702453613,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 45,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2665378aba90450180f1c1bdc66ac851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.380901575088501,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 12,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c0b27772e74092bc752b74ce07a6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_df = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b688e323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    }
   ],
   "source": [
    "tf_train_df = tok_df[\"train\"].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "tf_test_df = tok_df[\"test\"].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ffc9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_df) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e54305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   1/5502 [..............................] - ETA: 186:23:12 - loss: 1.3677"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul' defined at (most recent call last):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Wonder-David Efe\\AppData\\Local\\Temp\\ipykernel_21956\\479624844.py\", line 1, in <module>\n      model.fit(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1495, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1892, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 873, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 558, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 564, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 520, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 424, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul'\nOOM when allocating tensor with shape[8,491,3072] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27437]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_train_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;43;03m#     callbacks=[callback],\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul' defined at (most recent call last):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Wonder-David Efe\\AppData\\Local\\Temp\\ipykernel_21956\\479624844.py\", line 1, in <module>\n      model.fit(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1495, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1892, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1881, in run_call_with_unpacked_inputs\n      # Update base model and current model config\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 873, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 558, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 564, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 520, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 424, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Wonder-David Efe\\anaconda3\\envs\\nlpenv\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul'\nOOM when allocating tensor with shape[8,491,3072] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node tf_bert_for_token_classification/bert/encoder/layer_._6/intermediate/Gelu/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27437]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    tf_train_df,\n",
    "#     callbacks=[callback],\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6840870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
